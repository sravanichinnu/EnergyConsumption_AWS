{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4092790",
   "metadata": {},
   "source": [
    "# XGBoost Model Training & Hyperparameter Tuning\n",
    "\n",
    "This notebook trains an XGBoost regression model and performs grid-based hyperparameter tuning to improve forecast accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c99f66",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\n",
    "    \"s3://energy-consumption-forecasting-project/processed/pandas/pjme_energy_features.paruet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e286fb8f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "split_date = \"2017-01-01\"\n",
    "\n",
    "train_df = df[df[\"timestamp\"] < split_date]\n",
    "test_df = df[df[\"timestamp\"] >= split_date]\n",
    "\n",
    "x_train = train_df.drop(columns=[\"timestamp\", \"energy_mw\"])\n",
    "y_train = train_df[\"energy_mw\"]\n",
    "\n",
    "x_test = test_df.drop(columns=[\"timestamp\", \"energy_mw\"])\n",
    "y_test = test_df[\"energy_mw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2538457",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "baseline_model = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "baseline_model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bd9dc0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"max_depth\": [4, 6, 8],\n",
    "    \"learning_rate\": [0.03, 0.05, 0.1],\n",
    "    \"n_estimators\": [200, 300],\n",
    "    \"subsample\": [0.7, 0.8],\n",
    "    \"colsample_bytree\": [0.7, 0.8]\n",
    "}\n",
    "\n",
    "# creating a template model\n",
    "xgb = XGBRegressor(\n",
    "    random_state = 42,\n",
    "    onjective = \"reg:squarederror\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e1324d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# creating the GridSearch controller\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgb, # this is the type of model I want to tune. GridSearch will clone this estimator many times.\n",
    "    param_grid = param_grid, # these are the knobs I want to turn. GridSearch will iterate through all 72 combinations.\n",
    "    scoring = \"neg_root_mean_squared_error\", # RMSE should be minimized. scikit-learn always maximizes scores. so it uses negative RMSE\n",
    "    cv = 3, # 3 cross validations\n",
    "    verbose = 2,\n",
    "    n_jobs = -1 # use all available CPU coes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea39439",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e908d19a",
   "metadata": {},
   "source": [
    "Hyperparameter tuning reduced RMSE by ~8.8% compared to the baseline model. The tuned model was seelcted as the final forecasting model."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
